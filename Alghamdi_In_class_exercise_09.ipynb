{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Alghamdi_In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsmaaAlghamd1/Asmaa_INFO5731_-Spring2021/blob/main/Alghamdi_In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuSENWXtOZ_Q"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axNJ07B_OZ_Z"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuwnqXFOn4sg"
      },
      "source": [
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsz4gNm3OZ_a"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "Train_data = open('/content/stsa-train.txt').read()\n",
        "Train_label, Train_list = [], []\n",
        "for i, j in enumerate(Train_data.split(\"\\n\")):\n",
        "    c = j.split(' ')\n",
        "    Train_label.append(c[0])\n",
        "    Train_list.append(\" \".join(c[1:]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHJrkxSmD1-"
      },
      "source": [
        "Test_data = open('/content/stsa-test.txt').read()\n",
        "Test_label, Test_list = [], []\n",
        "for i, j in enumerate(test_data.split(\"\\n\")):\n",
        "    c = j.split(' ')\n",
        "    Test_label.append(c[0])\n",
        "    Test_list.append(\" \".join(c[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9bdrFCn6mJqq",
        "outputId": "6a3bebee-e0c9-4c20-cc65-92b581612be1"
      },
      "source": [
        "# creating data frame\n",
        "df = pd.DataFrame (list(zip(Train_list, Train_label)) , columns = ['Text', 'Labels'])\n",
        "Data_df= pd.DataFrame (list(zip(Test_list, Test_label)) , columns = ['Text', 'Labels'])\n",
        "Data_df = Data_df.dropna()\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6920</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6921 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Labels\n",
              "0     a stirring , funny and finally transporting re...      1\n",
              "1     apparently reassembled from the cutting-room f...      0\n",
              "2     they presume their audience wo n't sit still f...      0\n",
              "3     this is a visually stunning rumination on love...      1\n",
              "4     jonathan parker 's bartleby should have been t...      1\n",
              "...                                                 ...    ...\n",
              "6916  take care is nicely performed by a quintet of ...      0\n",
              "6917  the script covers huge , heavy topics in a bla...      0\n",
              "6918  a seriously bad film with seriously warped log...      0\n",
              "6919  a deliciously nonsensical comedy about a city ...      1\n",
              "6920                                                          \n",
              "\n",
              "[6921 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tDzucV-w-nMK",
        "outputId": "e0650a50-5047-4cb5-bbc7-f6255d8e1c92"
      },
      "source": [
        "Data_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1821</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1822 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Labels\n",
              "0        no movement , no yuks , not much of anything .      0\n",
              "1     a gob of drivel so sickly sweet , even the eag...      0\n",
              "2     gangs of new york is an unapologetic mess , wh...      0\n",
              "3     we never really feel involved with the story ,...      0\n",
              "4               this is one of polanski 's best films .      1\n",
              "...                                                 ...    ...\n",
              "1817  the problem with concept films is that if the ...      0\n",
              "1818  safe conduct , however ambitious and well-inte...      0\n",
              "1819  a film made with as little wit , interest , an...      0\n",
              "1820  but here 's the real damn : it is n't funny , ...      0\n",
              "1821                                                          \n",
              "\n",
              "[1822 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPmAFCuFmRYf",
        "outputId": "7ec8a9cf-7d91-42a3-f883-9cb530289e0f"
      },
      "source": [
        "\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "st = PorterStemmer()\n",
        "nltk.download('punkt')\n",
        "stop = stopwords.words('english')\n",
        "#Cleaning train data\n",
        "#Lower case\n",
        "df['Lowercasing'] = df['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "#Removing Punctuation\n",
        "df['Punctuation Removals'] = df['Lowercasing'].str.replace('[^\\w\\s]','')\n",
        "#Removing special charachters\n",
        "df['Aspecial charachters Removals'] = df['Punctuation Removals'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "#Removing stopwords\n",
        "df['Stopwords Removals'] = df['Punctuation Removals'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#Tokenization\n",
        "df['Tokenization'] = df['Stopwords Removals'].apply(lambda x: TextBlob(x).words)\n",
        "#Lemmatization\n",
        "df['Lemmatization'] = df['Tokenization'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fSbXminbuA-o",
        "outputId": "0c63aec4-994c-40ea-9344-11d065eb9dda"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Lowercasing</th>\n",
              "      <th>Punctuation Removals</th>\n",
              "      <th>Punctuation Removals</th>\n",
              "      <th>Aspecial charachters Removals</th>\n",
              "      <th>Stopwords Removals</th>\n",
              "      <th>Tokenization</th>\n",
              "      <th>Lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>a stirring  funny and finally transporting rei...</td>\n",
              "      <td>stirring funny finally transporting reimaginin...</td>\n",
              "      <td>[stirring, funny, finally, transporting, reima...</td>\n",
              "      <td>stirring funny finally transporting reimaginin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled from the cuttingroom fl...</td>\n",
              "      <td>apparently reassembled cuttingroom floor given...</td>\n",
              "      <td>[apparently, reassembled, cuttingroom, floor, ...</td>\n",
              "      <td>apparently reassembled cuttingroom floor given...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>they presume their audience wo nt sit still fo...</td>\n",
              "      <td>presume audience wo nt sit still sociology les...</td>\n",
              "      <td>[presume, audience, wo, nt, sit, still, sociol...</td>\n",
              "      <td>presume audience wo nt sit still sociology les...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "      <td>[visually, stunning, rumination, love, memory,...</td>\n",
              "      <td>visually stunning rumination love memory histo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker s bartleby should have been th...</td>\n",
              "      <td>jonathan parker bartleby beallendall modernoff...</td>\n",
              "      <td>[jonathan, parker, bartleby, beallendall, mode...</td>\n",
              "      <td>jonathan parker bartleby beallendall modernoff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>take care nicely performed quintet actresses n...</td>\n",
              "      <td>[take, care, nicely, performed, quintet, actre...</td>\n",
              "      <td>take care nicely performed quintet actress non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>the script covers huge  heavy topics in a blan...</td>\n",
              "      <td>the script covers huge  heavy topics in a blan...</td>\n",
              "      <td>the script covers huge  heavy topics in a blan...</td>\n",
              "      <td>script covers huge heavy topics bland surfacey...</td>\n",
              "      <td>[script, covers, huge, heavy, topics, bland, s...</td>\n",
              "      <td>script cover huge heavy topic bland surfacey w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>seriously bad film seriously warped logic writ...</td>\n",
              "      <td>[seriously, bad, film, seriously, warped, logi...</td>\n",
              "      <td>seriously bad film seriously warped logic writ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>deliciously nonsensical comedy city coming apa...</td>\n",
              "      <td>[deliciously, nonsensical, comedy, city, comin...</td>\n",
              "      <td>deliciously nonsensical comedy city coming apa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6920</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6921 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ...                                      Lemmatization\n",
              "0     a stirring , funny and finally transporting re...  ...  stirring funny finally transporting reimaginin...\n",
              "1     apparently reassembled from the cutting-room f...  ...  apparently reassembled cuttingroom floor given...\n",
              "2     they presume their audience wo n't sit still f...  ...  presume audience wo nt sit still sociology les...\n",
              "3     this is a visually stunning rumination on love...  ...  visually stunning rumination love memory histo...\n",
              "4     jonathan parker 's bartleby should have been t...  ...  jonathan parker bartleby beallendall modernoff...\n",
              "...                                                 ...  ...                                                ...\n",
              "6916  take care is nicely performed by a quintet of ...  ...  take care nicely performed quintet actress non...\n",
              "6917  the script covers huge , heavy topics in a bla...  ...  script cover huge heavy topic bland surfacey w...\n",
              "6918  a seriously bad film with seriously warped log...  ...  seriously bad film seriously warped logic writ...\n",
              "6919  a deliciously nonsensical comedy about a city ...  ...  deliciously nonsensical comedy city coming apa...\n",
              "6920                                                     ...                                                   \n",
              "\n",
              "[6921 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4kga8k2m55-"
      },
      "source": [
        "#cleaning test data\n",
        "Data_df['Lowercasing'] = Data_df['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "#Removing punctuation\n",
        "Data_df['Punctuation Removals'] = Data_df['Lowercasing'].str.replace('[^\\w\\s]','')\n",
        "#Removing special characters\n",
        "Data_df[' Special Characters Removals'] = Data_df['Punctuation Removals'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "#Removing stopwords\n",
        "Data_df['Stopwords Removals'] = Data_df['Punctuation Removals'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#Tokenization\n",
        "Data_df['Tokenization'] = Data_df['Stopwords Removals'].apply(lambda x: TextBlob(x).words)\n",
        "#Lemmatization\n",
        "Data_df['Lemmatization'] = Data_df['Tokenization'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KIE2KOayuMJl",
        "outputId": "fc6c83da-ee0a-48ed-cc22-f1b9f99778ea"
      },
      "source": [
        "Data_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Lowercasing</th>\n",
              "      <th>Punctuation Removals</th>\n",
              "      <th>Special Characters Removals</th>\n",
              "      <th>Stopwords Removals</th>\n",
              "      <th>Tokenization</th>\n",
              "      <th>Lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>no movement  no yuks  not much of anything</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "      <td>[movement, yuks, much, anything]</td>\n",
              "      <td>movement yuks much anything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>a gob of drivel so sickly sweet  even the eage...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumers m...</td>\n",
              "      <td>[gob, drivel, sickly, sweet, even, eager, cons...</td>\n",
              "      <td>gob drivel sickly sweet even eager consumer mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs of new york is an unapologetic mess  who...</td>\n",
              "      <td>gangs new york unapologetic mess whose saving ...</td>\n",
              "      <td>[gangs, new, york, unapologetic, mess, whose, ...</td>\n",
              "      <td>gang new york unapologetic mess whose saving g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>we never really feel involved with the story  ...</td>\n",
              "      <td>never really feel involved story ideas remain ...</td>\n",
              "      <td>[never, really, feel, involved, story, ideas, ...</td>\n",
              "      <td>never really feel involved story idea remain a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>this is one of polanski s best films</td>\n",
              "      <td>one polanski best films</td>\n",
              "      <td>[one, polanski, best, films]</td>\n",
              "      <td>one polanski best film</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>problem concept films concept poor one saving ...</td>\n",
              "      <td>[problem, concept, films, concept, poor, one, ...</td>\n",
              "      <td>problem concept film concept poor one saving m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>safe conduct  however ambitious and wellintent...</td>\n",
              "      <td>safe conduct  however ambitious and wellintent...</td>\n",
              "      <td>safe conduct however ambitious wellintentioned...</td>\n",
              "      <td>[safe, conduct, however, ambitious, wellintent...</td>\n",
              "      <td>safe conduct however ambitious wellintentioned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>a film made with as little wit  interest  and ...</td>\n",
              "      <td>a film made with as little wit  interest  and ...</td>\n",
              "      <td>film made little wit interest professionalism ...</td>\n",
              "      <td>[film, made, little, wit, interest, profession...</td>\n",
              "      <td>film made little wit interest professionalism ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>but here s the real damn  it is nt funny  either</td>\n",
              "      <td>but here s the real damn  it is nt funny  either</td>\n",
              "      <td>real damn nt funny either</td>\n",
              "      <td>[real, damn, nt, funny, either]</td>\n",
              "      <td>real damn nt funny either</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1821</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1822 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ...                                      Lemmatization\n",
              "0        no movement , no yuks , not much of anything .  ...                        movement yuks much anything\n",
              "1     a gob of drivel so sickly sweet , even the eag...  ...  gob drivel sickly sweet even eager consumer mo...\n",
              "2     gangs of new york is an unapologetic mess , wh...  ...  gang new york unapologetic mess whose saving g...\n",
              "3     we never really feel involved with the story ,...  ...  never really feel involved story idea remain a...\n",
              "4               this is one of polanski 's best films .  ...                             one polanski best film\n",
              "...                                                 ...  ...                                                ...\n",
              "1817  the problem with concept films is that if the ...  ...  problem concept film concept poor one saving m...\n",
              "1818  safe conduct , however ambitious and well-inte...  ...  safe conduct however ambitious wellintentioned...\n",
              "1819  a film made with as little wit , interest , an...  ...  film made little wit interest professionalism ...\n",
              "1820  but here 's the real damn : it is n't funny , ...  ...                          real damn nt funny either\n",
              "1821                                                     ...                                                   \n",
              "\n",
              "[1822 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpy69g1Qm-vn"
      },
      "source": [
        "#Data Transformation\n",
        "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector_train = TfidfVectorizer(analyzer='word')\n",
        "vector_train.fit(df['Lemmatization'])\n",
        "Tfidf =  vector_train.transform(df['Lemmatization'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw2Xb5eonG0i"
      },
      "source": [
        "\n",
        "vector_test = TfidfVectorizer(analyzer='word', vocabulary = vector_train.vocabulary_)\n",
        "vector_test.fit(Data_df['Lemmatization'])\n",
        "xtest = vector_test.transform(Data_df['Lemmatization'])\n",
        "test_y = Data_df['Labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1ChX6gMjmxB"
      },
      "source": [
        "from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(Tfidf,df['Labels'].values,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_WtaSYOjm7S"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "def validation_score(modelName, x, y):\n",
        "  scoring = 'accuracy'\n",
        "  kfold = KFold(10, random_state = 7,shuffle=True)\n",
        "  CV = cross_val_score(modelName, x, y, cv=kfold).mean()\n",
        "  return CV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHLrk6Fsj4o9"
      },
      "source": [
        "from sklearn import metrics\n",
        "def Metrics(predictions, test_data_y):\n",
        "  accuracy = metrics.accuracy_score(predictions, test_data_y)\n",
        "  precision = metrics.precision_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  recall = metrics.recall_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  f1 = metrics.f1_score(predictions, test_data_y, pos_label='positive', average='micro')\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5HFwwq8Ne36"
      },
      "source": [
        "## *MultinominalNB*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmy1K5_ojnFM",
        "outputId": "84a870e3-2ada-4938-eefc-c1ada2a7d8fc"
      },
      "source": [
        "NB_model = naive_bayes.MultinomialNB()\n",
        "NB_model.fit(train_x, train_y)\n",
        "NB_predictions= NB_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = Metrics(NB_predictions, valid_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "NB_scores = validation_score(naive_bayes_model, valid_x, valid_y)\n",
        "print('Navie Bayes Cross Validation Score is {0}'.format(NB_scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7653429602888087\n",
            "Precision is 0.7653429602888087\n",
            "Recall is 0.7653429602888087\n",
            "F1 is 0.7653429602888087\n",
            "_____________\n",
            "Navie Bayes Cross Validation Score is 0.686695860702742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yakXOtyMkGtb",
        "outputId": "3c876aee-6c24-4436-9cb0-fcca22102b39"
      },
      "source": [
        "\n",
        "NB_predict_test = NB_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = Metrics(NB_predict_test, test_y)\n",
        "print(\"Accuracy is {0}\\nPrecision is {1}\\nRecall is {2}\\nF1 is {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "NBtest_score = validation_score(naive_bayes_model, xtest, test_y)\n",
        "print('Navie Bayes Cross Validation Score is: {0}'.format(NBtest_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.7952799121844127\n",
            "Precision is 0.7952799121844127\n",
            "Recall is 0.7952799121844127\n",
            "F1 is 0.7952799121844127\n",
            "_____________\n",
            "Navie Bayes Cross Validation Score is: 0.7371044256290158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLtmiZJhNny2"
      },
      "source": [
        "# (SVM) Validation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGpmBxACkDnJ",
        "outputId": "a9581b0f-b5eb-43ba-a20f-de855803621b"
      },
      "source": [
        "SVM_model = svm.SVC()\n",
        "SVM_model.fit(train_x, train_y)\n",
        "SVM_predictions = SVM_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = Metrics(SVM_predictions, valid_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "SVM_score = validation_score(svm_model, valid_x, valid_y)\n",
        "print('SVM Cross Validation Score is: {0}'.format(SVM_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.7732851985559567\n",
            "Precision is: 0.7732851985559567\n",
            "Recall is: 0.7732851985559567\n",
            "F1 is: 0.7732851985559568\n",
            "_____________\n",
            "SVM Cross Validation Score is: 0.6693149827963716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1GJcRkbkDq5",
        "outputId": "7e29d2cd-87a5-4516-da8f-d24f13a9edfc"
      },
      "source": [
        "SVM_predict_test = SVM_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = Metrics(SVM_predict_test, test_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "SVMtest_score = validation_score(SVM_model, xtest, test_y)\n",
        "print('SVM Cross Validation Score is: {0}'.format(SVMtest_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.7936333699231614\n",
            "Precision is: 0.7936333699231614\n",
            "Recall is: 0.7936333699231614\n",
            "F1 is: 0.7936333699231614\n",
            "_____________\n",
            "SVM Cross Validation Score is: 0.7239086050561461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrGR_KpoNtAb"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiKmlmwAkDzz",
        "outputId": "fc0860f7-9609-43d5-c784-d8778cccfde9"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN_model = KNeighborsClassifier(n_neighbors = 15)\n",
        "KNN_model.fit(train_x, train_y)\n",
        "KNN_predictions = KNN_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = Metrics(KNN_predictions, valid_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "KNN_score = validation_score(KNN_model, valid_x, valid_y)\n",
        "print('KNN Cross Validation Score is: {0}'.format(KNN_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.7227436823104693\n",
            "Precision is: 0.7227436823104693\n",
            "Recall is: 0.7227436823104693\n",
            "F1 is: 0.7227436823104693\n",
            "_____________\n",
            "KNN Cross Validation Score is: 0.646105724116359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucxQV2q-kD6D",
        "outputId": "5cc83b86-df80-453c-da19-778ad9f6af7c"
      },
      "source": [
        "KNN_predict_test = KNN_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = Metrics(KNN_predict_test, test_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "KNNtest_score = validation_score(knn_model, xtest, test_y)\n",
        "print('KNN Cross Validation Score is: {0}'.format(KNNtest_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.7354555433589463\n",
            "Precision is: 0.7354555433589463\n",
            "Recall is: 0.7354555433589463\n",
            "F1 is: 0.7354555433589463\n",
            "_____________\n",
            "KNN Cross Validation Score is: 0.6361376328589443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg3RMkbqNy2y"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93FnWnxykD9o",
        "outputId": "91b7fcab-114f-4a7d-d44f-8f8390404e9c"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DT_model = DecisionTreeClassifier()\n",
        "DT_model.fit(train_x, train_y)\n",
        "DT_predictions = DT_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = Metrics(DT_predictions, valid_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "DT_score = validation_score(DT_model, valid_x, valid_y)\n",
        "print('Decision Tree Cross Validation Score is: {0}'.format(DT_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.6404332129963899\n",
            "Precision is: 0.6404332129963899\n",
            "Recall is: 0.6404332129963899\n",
            "F1 is: 0.6404332129963899\n",
            "_____________\n",
            "Decision Tree Cross Validation Score is: 0.5262954853508497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc-mMPgdmKr5",
        "outputId": "ecec1b37-6b45-409d-ff6a-e127b7ef1493"
      },
      "source": [
        "DT_predict_test= DT_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = Metrics(DT_predict_test, test_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "DTtest_score = validation_score(DT_model, xtest, test_y)\n",
        "print('Decision Tree Cross Validation Score is: {0}'.format(DTtest_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.6734357848518112\n",
            "Precision is: 0.6734357848518112\n",
            "Recall is: 0.6734357848518112\n",
            "F1 is: 0.6734357848518112\n",
            "_____________\n",
            "Decision Tree Cross Validation Score is: 0.6163183810724794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqh1aLVqN220"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty4X5zk2mOhD",
        "outputId": "a9e99768-c3ab-4e3c-cacb-dd6c50fbca9e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF_model = RandomForestClassifier()\n",
        "RF_model.fit(train_x, train_y)\n",
        "RF_predictions = RF_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = Metrics(RF_predictions, valid_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "RF_score = validation_score(RF_model, valid_x, valid_y)\n",
        "print('Random Forest Cross Validation Score is: {0}'.format(RF_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.7104693140794224\n",
            "Precision is: 0.7104693140794224\n",
            "Recall is: 0.7104693140794224\n",
            "F1 is: 0.7104693140794224\n",
            "_____________\n",
            "Random Forest Cross Validation Score is: 0.6245490564070483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N59b5fzpmXCN",
        "outputId": "01d12b6d-eaa1-4cf9-c8de-0888fc19dffb"
      },
      "source": [
        "RF_predict_test = RF_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = Metrics(RF_predict_test, test_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "RFtest_score = validation_score(RF_model, xtest, test_y)\n",
        "print('Random Forest Cross Validation Score is: {0}'.format(RFtest_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.7403951701427003\n",
            "Precision is: 0.7403951701427003\n",
            "Recall is: 0.7403951701427003\n",
            "F1 is: 0.7403951701427003\n",
            "_____________\n",
            "Random Forest Cross Validation Score is: 0.6553323725454873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szAU6T-RN4h_"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7dAOrrumdGM",
        "outputId": "48bcb2ea-a571-44ba-8652-094dcfebcac7"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "XG_model = XGBClassifier()\n",
        "XG_model.fit(train_x, train_y)\n",
        "XG_predictions= XG_model.predict(valid_x)\n",
        "accuracy, precision, recall, f1 = Metrics(XG_predictions, valid_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "XG_score = validation_score(XGBClassifier(), valid_x, valid_y)\n",
        "print('XG Boost Cross Validation Score is {0}'.format(XG_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.636101083032491\n",
            "Precision is: 0.636101083032491\n",
            "Recall is: 0.636101083032491\n",
            "F1 is: 0.636101083032491\n",
            "_____________\n",
            "XG Boost Cross Validation Score is 0.6180377437180691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DVMfGcbmiAF",
        "outputId": "e5e44e1e-230f-43c9-a5ce-96548d78bf68"
      },
      "source": [
        "XG_predict_test= XG_model.predict(xtest)\n",
        "accuracy, precision, recall, f1 = Metrics(XG_predict_test, test_y)\n",
        "print(\"Accuracy is: {0}\\nPrecision is: {1}\\nRecall is: {2}\\nF1 is: {3}\".format(accuracy, precision, recall, f1))\n",
        "print(\"_____________\")\n",
        "XGtest_score = validation_score(XGBClassifier(), xtest, test_y)\n",
        "print('XG Boost Cross Validation Score is: {0}'.format(XGtest_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1321: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
            "  % (pos_label, average), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.6267837541163557\n",
            "Precision is: 0.6267837541163557\n",
            "Recall is: 0.6267837541163557\n",
            "F1 is: 0.6267837541163557\n",
            "_____________\n",
            "XG Boost Cross Validation Score is: 0.6251035849396506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAL7m-zcmHic"
      },
      "source": [
        "The accuracy of the models as following\n",
        "\n",
        "Navie Bayes - 77%\n",
        "\n",
        "SVM - 78%\n",
        "\n",
        "KNN - 72%\n",
        "\n",
        "Decision Tree - 64%\n",
        "\n",
        "Random Forest - 71%\n",
        "\n",
        "XG Boost - 63.6%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dUxCKv1oDGK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}